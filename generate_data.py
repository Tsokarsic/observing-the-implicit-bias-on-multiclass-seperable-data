from os import SEEK_DATA

from scipy.stats import chi2  # ç”¨äºÏ‡Â²åˆ†å¸ƒéªŒè¯
import warnings
import numpy as np
import pandas as pd
import json
import cvxpy as cp
from scipy.spatial.distance import pdist, squareform
import torch
import torch.nn as nn
import torch.optim as optim
from selenium.webdriver.common.devtools.v135.page import start_screencast
from torch.utils.data import TensorDataset, DataLoader

warnings.filterwarnings("ignore")  # å¿½ç•¥æ•°å€¼è®¡ç®—è­¦å‘Š


def compute_highdim_gaussian_cutoff(d: int, sigma: float, confidence: float = 0.99) -> float:
    """
    è®¡ç®—é«˜ç»´é«˜æ–¯å™ªå£°çš„åˆç†æˆªæ–­åŠå¾„Rï¼ˆåŸºäºÏ‡Â²åˆ†å¸ƒçš„ç½®ä¿¡åŒºé—´ï¼‰
    å‚æ•°ï¼š
        d: ç‰¹å¾ç»´åº¦
        sigma: é«˜æ–¯å™ªå£°æ ‡å‡†å·®
        confidence: ç½®ä¿¡æ°´å¹³ï¼ˆå¦‚0.99ï¼Œè¦†ç›–99%çš„åŸå§‹é«˜æ–¯æ ·æœ¬ï¼‰
    è¿”å›ï¼š
        R: æˆªæ–­åŠå¾„ï¼ˆL2èŒƒæ•°ä¸Šé™ï¼‰
    """
    # 1. é«˜æ–¯èŒƒæ•°å¹³æ–¹çš„åˆ†å¸ƒï¼šÏƒÂ²Â·Ï‡Â²(d)
    chi2_df = float(d)  # Ï‡Â²åˆ†å¸ƒè‡ªç”±åº¦
    chi2_quantile = chi2.ppf(confidence, df=chi2_df)  # Ï‡Â²åˆ†å¸ƒçš„confidenceåˆ†ä½æ•°
    # 2. è®¡ç®—æˆªæ–­åŠå¾„çš„å¹³æ–¹ï¼ˆåŸºäºÏ‡Â²åˆ†ä½æ•°ï¼‰
    cutoff_norm_sq = sigma ** 2 * chi2_quantile
    R = np.sqrt(cutoff_norm_sq)

    # 3. æ‰“å°ç†è®ºç»Ÿè®¡ä¿¡æ¯ï¼ˆå¸®åŠ©éªŒè¯åˆç†æ€§ï¼‰
    print(f"ğŸ“Š é«˜ç»´é«˜æ–¯æˆªæ–­å‚æ•°ï¼ˆd={d}, Ïƒ={sigma}ï¼‰ï¼š")
    print(f"   - æˆªæ–­åŠå¾„Rï¼ˆè¦†ç›–{confidence * 100}%æ ·æœ¬ï¼‰ï¼š{R:.4f}")
    print(f"   - æˆªæ–­åŠå¾„å¯¹åº”çš„èŒƒæ•°å¹³æ–¹ï¼š{cutoff_norm_sq:.4f}")
    return R


def generate_highdim_gaussian_noise(
        d: int, sigma: float, R: float, max_retries: int = 1000
) -> np.ndarray:
    """
    ç”Ÿæˆé«˜ç»´é«˜æ–¯å™ªå£°ï¼ˆçº¦æŸåœ¨L2çƒå†…ï¼‰ï¼Œè¿”å›ç¬¦åˆæ¡ä»¶åˆ†å¸ƒçš„å™ªå£°
    æ–¹æ³•ï¼šæ‹’ç»é‡‡æ ·æ³•ï¼Œç¡®ä¿åˆ†å¸ƒä¸º Îµ | ||Îµ||â‚‚ â‰¤ R
    """
    for i in range(max_retries):
        # 1. ç”ŸæˆåŸå§‹é«˜æ–¯å™ªå£°
        noise = np.random.normal(loc=0, scale=sigma, size=d)
        # 2. æˆªæ–­åˆ¤æ–­ï¼ˆL2èŒƒæ•°â‰¤Råˆ™æ¥å—ï¼‰
        noise_norm = np.linalg.norm(noise)
        if noise_norm <= R + 1e-8:  # åŠ 1e-8é¿å…æµ®ç‚¹è¯¯å·®
            return noise
    # å…œåº•æœºåˆ¶ï¼šè‹¥é‡è¯•ä¸Šé™ä»æœªæ»¡è¶³ï¼Œè¿”å›èŒƒæ•°=Rçš„å™ªå£°ï¼ˆé¿å…æ— é™å¾ªç¯ï¼‰
    warnings.warn(f"âš ï¸ é‡é‡‡æ ·{max_retries}æ¬¡æœªè¾¾æ ‡ï¼Œè¿”å›èŒƒæ•°=Rçš„å™ªå£°ï¼ˆè¿‘ä¼¼æ¡ä»¶åˆ†å¸ƒï¼‰")
    noise = np.random.normal(loc=0, scale=sigma, size=d)
    noise = noise / np.linalg.norm(noise) * R  # å½’ä¸€åŒ–åˆ°èŒƒæ•°=R
    return noise


def generate_samples_with_highdim_cutoff(
        class_centers: np.ndarray,  # ç±»ä¸­å¿ƒ(k, d)
        n_per_class: int = 50,  # æ¯ç±»æ ·æœ¬æ•°
        sigma: float = 0.1,  # å™ªå£°æ ‡å‡†å·®
        confidence: float = 0.99,  # æˆªæ–­è¦†ç›–çš„ç½®ä¿¡åº¦
        max_noise_retries: int = 1000  # å™ªå£°é‡é‡‡æ ·ä¸Šé™
) -> tuple[np.ndarray, np.ndarray]:
    """
    ç”Ÿæˆå¸¦é«˜ç»´åˆç†æˆªæ–­å™ªå£°çš„æ ·æœ¬ï¼Œè¿”å›(X, y)
    æ ¸å¿ƒï¼šå™ªå£°æ˜¯é«˜æ–¯åœ¨çƒå†…çš„æ¡ä»¶åˆ†å¸ƒï¼Œè€Œéç®€å•3Ïƒæˆªæ–­
    """
    k, d = class_centers.shape
    X, y = [], []

    # 1. è®¡ç®—é«˜ç»´é«˜æ–¯çš„åˆç†æˆªæ–­åŠå¾„R
    R = compute_highdim_gaussian_cutoff(d=d, sigma=sigma, confidence=confidence)

    # 2. ä¸ºæ¯ç±»ç”Ÿæˆæ ·æœ¬ï¼ˆå¸¦æ¡ä»¶åˆ†å¸ƒå™ªå£°ï¼‰
    for class_idx in range(k):
        class_samples = []
        # è®°å½•å™ªå£°èŒƒæ•°ç»Ÿè®¡ï¼ˆç”¨äºéªŒè¯åˆ†å¸ƒï¼‰
        noise_norms = []
        while len(class_samples) < n_per_class:
            # ç”Ÿæˆç¬¦åˆæ¡ä»¶åˆ†å¸ƒçš„å™ªå£°
            noise = generate_highdim_gaussian_noise(
                d=d, sigma=sigma, R=R, max_retries=max_noise_retries
            )
            # ç”Ÿæˆæ ·æœ¬ï¼ˆä¸­å¿ƒ+å™ªå£°ï¼‰
            sample = class_centers[class_idx] + noise
            class_samples.append(sample)
            # è®°å½•å™ªå£°èŒƒæ•°ï¼ˆåç»­éªŒè¯ï¼‰
            noise_norms.append(np.linalg.norm(noise))

        # 3. éªŒè¯å½“å‰ç±»çš„å™ªå£°åˆ†å¸ƒï¼ˆæ‰“å°ç»Ÿè®¡ä¿¡æ¯ï¼‰
        noise_norms = np.array(noise_norms)
        print(f"ğŸ“ˆ ç¬¬{class_idx + 1}ç±»å™ªå£°èŒƒæ•°ç»Ÿè®¡ï¼ˆæ¡ä»¶åˆ†å¸ƒï¼‰ï¼š")
        print(f"   - å‡å€¼ï¼š{noise_norms.mean():.4f} | ç†è®ºå‡å€¼ï¼š{R * (d / (d + 2)):.4f}")  # æ¡ä»¶åˆ†å¸ƒå‡å€¼è¿‘ä¼¼
        print(f"   - æ ‡å‡†å·®ï¼š{noise_norms.std():.4f}")
        print(f"   - æœ€å¤§èŒƒæ•°ï¼š{noise_norms.max():.4f} â‰¤ R={R:.4f}ï¼ˆæˆªæ–­æœ‰æ•ˆï¼‰\n")

        X.append(np.array(class_samples))
        y.extend([class_idx] * n_per_class)

    # æ ¼å¼è½¬æ¢
    X = np.vstack(X)
    y = np.array(y)
    return X, y


# -------------------------- æ•´åˆåˆ°åŸæœ‰æ•°æ®ç”Ÿæˆæµç¨‹ --------------------------
def generate_standard_gaussian_data(
        k: int = 10, d: int = 25, n_per_class: int = 50, sigma: float = 0.1,
        max_center_retries: int = 100, seed: int = 42, regenerate: bool = True,
        save_dir: str = "./experiment_data/"
) -> tuple[np.ndarray, np.ndarray, np.ndarray, dict, dict]:
    """
    æ”¹è¿›åçš„æ•°æ®ç”Ÿæˆå‡½æ•°ï¼šç”¨é«˜ç»´æ¡ä»¶åˆ†å¸ƒå™ªå£°æ›¿æ¢åŸ3Ïƒæˆªæ–­
    """
    import os
    os.makedirs(save_dir, exist_ok=True)
    json_path = os.path.join(save_dir, "data_with_highdim_noise.json")

    # åŠ è½½å·²æœ‰æ•°æ®ï¼ˆç•¥ï¼ŒåŒåŸé€»è¾‘ï¼‰
    if not regenerate and os.path.exists(json_path):
        with open(json_path, "r", encoding="utf-8") as f:
            data_dict = json.load(f)
        X = np.array(data_dict["X"])
        y = np.array(data_dict["y"])
        class_centers = np.array(data_dict["class_centers"])
        data_params = data_dict["data_params"]
        margin_dict = data_dict["max_margin"]
        return X, y, class_centers, data_params, margin_dict

    # ç”Ÿæˆç±»ä¸­å¿ƒï¼ˆç•¥ï¼ŒåŒåŸé€»è¾‘ï¼šæ ‡å‡†é«˜æ–¯+è·ç¦»éªŒè¯ï¼‰
    np.random.seed(seed)
    retry_count = 0
    class_centers = None
    min_dist_threshold = 2 * (compute_highdim_gaussian_cutoff(d=d, sigma=sigma, confidence=0.99)) + 0.5
    while retry_count < max_center_retries:
        candidate_centers = np.random.normal(0, 1, (k, d))
        current_min_dist = compute_min_center_distance(candidate_centers)
        if current_min_dist >= min_dist_threshold:
            class_centers = candidate_centers
            print(f"âœ… ç±»ä¸­å¿ƒç”Ÿæˆï¼šæœ€å°è·ç¦»={current_min_dist:.4f}â‰¥{min_dist_threshold:.4f}\n")
            break
        retry_count += 1
    if class_centers is None:
        candidate_centers = np.random.normal(0, 1, (k, d))
        current_min_dist = compute_min_center_distance(candidate_centers)
        scale_factor = min_dist_threshold / current_min_dist
        class_centers = candidate_centers * scale_factor
        print(f"âš ï¸ ç±»ä¸­å¿ƒæ‰‹åŠ¨ç¼©æ”¾ï¼šç³»æ•°={scale_factor:.2f}\n")

    # -------------------------- å…³é”®æ”¹è¿›ï¼šç”¨é«˜ç»´æ¡ä»¶åˆ†å¸ƒå™ªå£°ç”Ÿæˆæ ·æœ¬ --------------------------
    X, y = generate_samples_with_highdim_cutoff(
        class_centers=class_centers,
        n_per_class=n_per_class,
        sigma=sigma,
        confidence=0.99,  # è¦†ç›–99%çš„é«˜æ–¯æ ·æœ¬
        max_noise_retries=1000
    )

    # åç»­è®¡ç®—max marginã€ä¿å­˜JSON/CSVï¼ˆåŒåŸé€»è¾‘ï¼Œç•¥ï¼‰
    margin_dict = compute_multinorm_max_margin(X, y)
    sample_df = pd.DataFrame(X, columns=[f"feat_{i + 1}" for i in range(d)])
    sample_df["label"] = y
    sample_df.to_csv(os.path.join(save_dir, "samples_highdim.csv"), index=False)

    data_params = {
        "k": k, "d": d, "n_per_class": n_per_class, "sigma": sigma,
        "seed": seed, "cutoff_R": compute_highdim_gaussian_cutoff(d=d, sigma=sigma, confidence=0.99),
        "center_min_dist": compute_min_center_distance(class_centers), "n_total": len(X)
    }
    data_dict = {
        "X": X.tolist(), "y": y.tolist(), "class_centers": class_centers.tolist(),
        "data_params": data_params, "max_margin": margin_dict
    }
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(data_dict, f, indent=4)
    print(f"ğŸ’¾ æ”¹è¿›åæ•°æ®ä¿å­˜è‡³ï¼š{json_path}")

    return X, y, class_centers, data_params, margin_dict


# -------------------------- è¾…åŠ©å‡½æ•°ï¼ˆåŒåŸé€»è¾‘ï¼Œéœ€ä¿ç•™ï¼‰ --------------------------
def compute_min_center_distance(class_centers: np.ndarray) -> float:
    from scipy.spatial.distance import pdist, squareform
    dist_matrix = squareform(pdist(class_centers, metric="euclidean"))
    return round(np.min(dist_matrix[np.nonzero(dist_matrix)]), 4)




import cvxpy as cp
import numpy as np
import time


def compute_multinorm_max_margin(X: np.ndarray, y: np.ndarray) -> dict:
    """
    æ±‚è§£ä¸åŒèŒƒæ•°çº¦æŸä¸‹çš„æœ€å¤§é—´éš” (Max Margin) é—®é¢˜ã€‚
    - L2/Linf ä½¿ç”¨ ECOS æ±‚è§£å™¨ã€‚
    - è°±èŒƒæ•° (Spectral Norm) åˆ‡æ¢ä¸º CVXOPT æ±‚è§£å™¨ã€‚
    - æ±‚è§£å¤±è´¥æ—¶ä¸å›é€€ï¼Œç›´æ¥æŠ¥é”™ã€‚
    """
    n, d = X.shape
    k = len(np.unique(y))
    margin_dict = {}

    # èŒƒæ•°é…ç½®ï¼šåŠ å…¥è°±èŒƒæ•°
    norm_configs = [
        ("L2_norm", lambda W: cp.norm(W, "fro") <= 1),
        ("Linf_norm", lambda W: cp.norm(W, "inf") <= 1),
        ("spectral_norm", lambda W: cp.norm(W, 2) <= 1)
    ]

    for norm_name, constraint_fn in norm_configs:
        print(f"\n" + "=" * 80)
        print(f"ğŸ“Œ æ±‚è§£ {norm_name} çš„ max margin")
        print("=" * 80)

        # 1. æ„å»ºä¼˜åŒ–é—®é¢˜ (ä¿æŒä¸å˜)
        W = cp.Variable((k, d), name="weight_matrix")
        margin_exprs = []
        for i in range(n):
            x_i = X[i].reshape(-1, 1)
            y_i = y[i]
            for c in range(k):
                if c != y_i:
                    e_diff = np.zeros((k, 1))
                    e_diff[y_i] = 1
                    e_diff[c] = -1
                    margin = cp.matmul(e_diff.T, cp.matmul(W, x_i))
                    margin_exprs.append(margin)

        if not margin_exprs:
            raise RuntimeError(f"âŒ {norm_name}ï¼šæ— æœ‰æ•ˆé—´éš”è¡¨è¾¾å¼")
        margins_vec = cp.vstack(margin_exprs)
        min_margin = cp.min(margins_vec)
        objective = cp.Maximize(min_margin)
        constraints = [constraint_fn(W)]

        # 2. åŠ¨æ€æ±‚è§£å™¨å’Œå‚æ•°é€‰æ‹©
        if norm_name == "spectral_norm":
            solver = cp.CVXOPT
            solver_name = "CVXOPT (for SDP)"
            solver_opts = {"verbose": True, "max_iters": 1000, "abstol": 1e-4,
                "reltol": 1e-4,
                "feastol": 1e-4}
        else:
            solver = cp.ECOS
            solver_name = "ECOS"
            solver_opts = {"verbose": True, "max_iters": 1000, "abstol": 1e-9, "reltol": 1e-9}

        # 3. è°ƒç”¨æ±‚è§£å™¨
        print(f"ğŸš€ å¼€å§‹æ±‚è§£ï¼š{norm_name}ï¼Œæ±‚è§£å™¨ï¼š{solver_name}")
        prob = cp.Problem(objective, constraints)

        try:
            prob.solve(solver=solver, **solver_opts)
        except cp.error.SolverError as e:
            # ä¸å›é€€ï¼Œç›´æ¥æŠ¥é”™
            raise RuntimeError(f"âŒ {norm_name} æ±‚è§£å¤±è´¥ï¼è¯·ç¡®ä¿å·²å®‰è£… {solver_name}ã€‚åŸå§‹é”™è¯¯ï¼š{e}")

        # 4. ç»“æœå¤„ç† (ä½¿ç”¨ np.round ä¿®æ­£ç±»å‹é”™è¯¯)
        if prob.status in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:
            final_gamma_value = min_margin.value
            final_W_value = W.value

            # ç¡®ä¿æœ€ç»ˆ gamma æ˜¯ float æˆ– list
            if final_gamma_value is not None:
                final_gamma = np.round(final_gamma_value, 6)
                final_gamma = final_gamma.item() if np.isscalar(final_gamma) else final_gamma.tolist()
            else:
                final_gamma = 0.0

            # ç¡®ä¿æœ€ç»ˆ W æ˜¯ list
            if final_W_value is not None:
                final_W_np = np.round(final_W_value, 6)  # å…ˆè½¬ä¸º numpy
                final_W = final_W_np.tolist()
            else:
                final_W_np = np.zeros((k, d))
                final_W = final_W_np.tolist()

            margin_dict[norm_name] = {
                "gamma": final_gamma,
                "matrix": final_W
            }

            # æ¢å¤åŸæœ‰æ‰“å°é€»è¾‘ (æ‰“å° W çš„å‰ 3 è¡Œé¢„è§ˆ)
            print(f"\nâœ… {norm_name}æ±‚è§£æˆåŠŸï¼")
            print(f" Â  - æ±‚è§£çŠ¶æ€ï¼š{prob.status}")
            print(f" Â  - æœ€ç»ˆgammaï¼ˆæœ€å°é—´éš”ï¼‰ï¼š{final_gamma}")
            print(f" Â  - æƒé‡çŸ©é˜µWï¼š{final_W}")

        else:
            raise RuntimeError(f"âŒ {norm_name}æœªæ”¶æ•›ï¼çŠ¶æ€ï¼š{prob.status}ï¼Œå»ºè®®è°ƒæ•´æ±‚è§£å™¨å‚æ•°ã€‚")

    return margin_dict
# def compute_multinorm_max_margin(X: np.ndarray, y: np.ndarray) -> dict:
#     """
#     å…¼å®¹ç‰ˆæ±‚è§£å™¨ï¼šåˆ‡æ¢è‡³ ECOS æ±‚è§£å™¨ï¼Œé¿å… SCS çš„åº•å±‚è§£æé”™è¯¯ã€‚
#     """
#     # ... (å‰ç•¥ï¼šæ•°æ®æ£€æŸ¥ã€k, d, margin_dict åˆå§‹åŒ–ä¸å˜) ...
#
#     n, d = X.shape
#     k = len(np.unique(y))
#     margin_dict = {}
#
#     # èŒƒæ•°é…ç½®ï¼ˆä¸å˜ï¼Œæˆ‘ä»¬å…ˆå°è¯•æ›´æ¢æ±‚è§£å™¨æ¥è§£å†³é—®é¢˜ï¼‰
#     norm_configs = [
#         ("L2_norm", lambda W: cp.norm(W, "fro") <= 1),
#         ("Linf_norm", lambda W: cp.norm(W, "inf") <= 1),
#         # ("spectral_norm", lambda W: cp.norm(W, 2) <= 1)
#     ]
#
#     for norm_name, constraint_fn in norm_configs:
#         print(f"\n" + "=" * 80)
#         print(f"ğŸ“Œ å°è¯•ä½¿ç”¨ ECOS æ±‚è§£å™¨æ±‚è§£ {norm_name} çš„ max margin")
#         print("=" * 80)
#
#         # 1. æ„å»ºä¼˜åŒ–é—®é¢˜ï¼ˆç•¥ï¼Œä¸åŸä»£ç å®Œå…¨ç›¸åŒï¼Œä¸å˜ï¼‰
#         W = cp.Variable((k, d), name="weight_matrix")
#         margin_exprs = []
#         for i in range(n):
#             x_i = X[i].reshape(-1, 1)
#             y_i = y[i]
#             for c in range(k):
#                 if c != y_i:
#                     e_diff = np.zeros((k, 1))
#                     e_diff[y_i] = 1
#                     e_diff[c] = -1
#                     margin = cp.matmul(e_diff.T, cp.matmul(W, x_i))
#                     margin_exprs.append(margin)
#
#         if not margin_exprs:
#             raise RuntimeError(f"âŒ {norm_name}ï¼šæ— æœ‰æ•ˆé—´éš”è¡¨è¾¾å¼")
#         margins_vec = cp.vstack(margin_exprs)
#         min_margin = cp.min(margins_vec)
#         objective = cp.Maximize(min_margin)
#         constraints = [constraint_fn(W)]
#
#         # 2. æ±‚è§£å™¨å‚æ•°ï¼ˆä¸º ECOS ä¼˜åŒ–ï¼‰
#         solver_opts = {
#             "verbose": True,  # æ‰“å¼€æ—¥å¿—
#             "max_iters": 1000,  # ECOS ä½¿ç”¨ max_iters
#             "abstol": 1e-9,  # ç»å¯¹ç²¾åº¦
#             "reltol": 1e-9  # ç›¸å¯¹ç²¾åº¦
#         }
#
#         # 3. æ ¸å¿ƒä¿®æ”¹ï¼šè°ƒç”¨ ECOS æ±‚è§£
#         print(f"ğŸš€ å¼€å§‹æ±‚è§£ï¼š{norm_name}ï¼Œæ±‚è§£å™¨ï¼šECOS")
#         prob = cp.Problem(objective, constraints)
#
#         # âš ï¸ å°† solver=cp.SCS æ›¿æ¢ä¸º solver=cp.ECOS
#         prob.solve(
#             solver=cp.ECOS,
#             **solver_opts
#         )
#
#         # 4. ç»“æœå¤„ç†ï¼ˆç•¥ï¼Œä¸åŸä»£ç å®Œå…¨ç›¸åŒï¼Œä¸å˜ï¼‰
#         if prob.status in [cp.OPTIMAL, cp.OPTIMAL_INACCURATE]:
#             final_gamma = np.round(min_margin.value, 6) if min_margin.value is not None else 0.0
#             final_W = np.round(W.value, 6) if W.value is not None else np.zeros((k, d))
#             margin_dict[norm_name] = {
#                 "gamma": final_gamma.tolist(),
#                 "matrix": final_W.tolist()
#             }
#             print(f"\nâœ… {norm_name}æ±‚è§£æˆåŠŸï¼")
#             print(f" Â  - æ±‚è§£çŠ¶æ€ï¼š{prob.status}")
#             print(f" Â  - æœ€ç»ˆgammaï¼ˆæœ€å°é—´éš”ï¼‰ï¼š{final_gamma}")
#             # ... (æ‰“å°çŸ©é˜µé¢„è§ˆ) ...
#             print(f" Â  - æœ€ç»ˆçŸ©é˜µï¼ˆæœ€å°é—´éš”ï¼‰ï¼š{final_W}")
#         else:
#             raise RuntimeError(f"âŒ {norm_name}æœªæ”¶æ•›ï¼çŠ¶æ€ï¼š{prob.status}ï¼Œå»ºè®®å¢å¤§max_iters")
#
#     return margin_dict


# -------------------------- æµ‹è¯•æ”¹è¿›æ•ˆæœ --------------------------
if __name__ == "__main__":
    SEED=45
    # ç”Ÿæˆæ”¹è¿›åçš„æ•°æ®ï¼ˆd=25ï¼ŒÏƒ=0.1ï¼Œé«˜ç»´æ¡ä»¶åˆ†å¸ƒå™ªå£°ï¼‰
    X, y, centers, params, margin = generate_standard_gaussian_data(
        k=10, d=25, n_per_class=50, sigma=0.1, regenerate=True, seed=SEED
    )
    print(f"\nâœ… æ•°æ®ç”Ÿæˆå®Œæˆï¼š{len(X)}æ ·æœ¬ï¼Œå™ªå£°ä¸ºé«˜ç»´é«˜æ–¯æ¡ä»¶åˆ†å¸ƒï¼ˆæˆªæ–­åŠå¾„R={params['cutoff_R']:.4f}ï¼‰")